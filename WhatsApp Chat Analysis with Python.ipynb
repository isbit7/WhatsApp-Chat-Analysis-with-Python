{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d334efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-1.5.0.tar.gz (185 kB)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-1.5.0-py3-none-any.whl size=187441 sha256=2975963f0d784abe832b210cf5c1284b031480d2716bd478fb397194989ef59e\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\e9\\d5\\46\\33c9101a710eb267fbaf8572c96fce5b12702e62bb5fa40592\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-1.5.0\n"
     ]
    }
   ],
   "source": [
    "! pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b40022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordCloud\n",
      "  Downloading wordcloud-1.8.1-cp38-cp38-win_amd64.whl (155 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wordCloud) (1.20.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wordCloud) (8.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wordCloud) (3.3.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordCloud) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordCloud) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordCloud) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordCloud) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordCloud) (1.15.0)\n",
      "Installing collected packages: wordCloud\n",
      "Successfully installed wordCloud-1.8.1\n"
     ]
    }
   ],
   "source": [
    "! pip install wordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0509e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a966056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_time(s):\n",
    "    pattern = '^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -'\n",
    "    result = regex.match(pattern, s)\n",
    "    if result:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def find_author(s):\n",
    "    s = s.split(\":\")\n",
    "    if len(s)==2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def getDatapoint(line):\n",
    "    splitline = line.split(' - ')\n",
    "    dateTime = splitline[0]\n",
    "    date, time = dateTime.split(\", \")\n",
    "    message = \" \".join(splitline[1:])\n",
    "    if find_author(message):\n",
    "        splitmessage = message.split(\": \")\n",
    "        author = splitmessage[0]\n",
    "        message = \" \".join(splitmessage[1:])\n",
    "    else:\n",
    "        author= None\n",
    "    return date, time, author, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93567c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "conversation = 'WhatsApp Chat - Tanya Duo.txt'\n",
    "with open(conversation, encoding=\"utf-8\") as fp:\n",
    "    fp.readline()\n",
    "    messageBuffer = []\n",
    "    date, time, author = None, None, None\n",
    "    while True:\n",
    "        line = fp.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        if date_time(line):\n",
    "            if len(messageBuffer) > 0:\n",
    "                data.append([date, time, author, ' '.join(messageBuffer)])\n",
    "            messageBuffer.clear()\n",
    "            date, time, author, message = getDatapoint(line)\n",
    "            messageBuffer.append(message)\n",
    "        else:\n",
    "            messageBuffer.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf0a3a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Date, Time, Author, Message]\n",
      "Index: []\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   Date     0 non-null      datetime64[ns]\n",
      " 1   Time     0 non-null      object        \n",
      " 2   Author   0 non-null      object        \n",
      " 3   Message  0 non-null      object        \n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 0.0+ bytes\n",
      "None\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=[\"Date\", 'Time', 'Author', 'Message'])\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(df.tail(20))\n",
    "print(df.info())\n",
    "print(df.Author.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd875e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "total_messages = df.shape[0]\n",
    "print(total_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_messages = df[df[\"Message\"]=='<Media omitted>'].shape[0]\n",
    "print(media_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_count(text):\n",
    "    emoji_list = []\n",
    "    data = regex.findall(r'\\X',text)\n",
    "    for word in data:\n",
    "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "            emoji_list.append(word)\n",
    "    return emoji_list\n",
    "df['emoji'] = df[\"Message\"].apply(split_count)\n",
    "\n",
    "emojis = sum(df['emoji'].str.len())\n",
    "print(emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c31d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPATTERN = r'(https?://\\S+)'\n",
    "df['urlcount'] = df.Message.apply(lambda x: regex.findall(URLPATTERN, x)).str.len()\n",
    "links = np.sum(df.urlcount)\n",
    "\n",
    "print(\"Chats between Indra and Tanya\")\n",
    "print(\"Total Messages: \", total_messages)\n",
    "print(\"Number of Media Shared: \", media_messages)\n",
    "print(\"Number of Emojis Shared\", emojis)\n",
    "print(\"Number of Links Shared\", links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed216f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_messages_df = df[df['Message'] == '<Media omitted>']\n",
    "messages_df = df.drop(media_messages_df.index)\n",
    "messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s : len(s))\n",
    "messages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))\n",
    "messages_df[\"MessageCount\"]=1\n",
    "\n",
    "l = [\"Indra\", \"Tanya\"]\n",
    "for i in range(len(l)):\n",
    "  # Filtering out messages of particular user\n",
    "  req_df= messages_df[messages_df[\"Author\"] == l[i]]\n",
    "  # req_df will contain messages of only one particular user\n",
    "  print(f'Stats of {l[i]} -')\n",
    "  # shape will print number of rows which indirectly means the number of messages\n",
    "  print('Messages Sent', req_df.shape[0])\n",
    "  #Word_Count contains of total words in one message. Sum of all words/ Total Messages will yield words per message\n",
    "  words_per_message = (np.sum(req_df['Word_Count']))/req_df.shape[0]\n",
    "  print('Average Words per message', words_per_message)\n",
    "  #media conists of media messages\n",
    "  media = media_messages_df[media_messages_df['Author'] == l[i]].shape[0]\n",
    "  print('Media Messages Sent', media)\n",
    "  # emojis conists of total emojis\n",
    "  emojis = sum(req_df['emoji'].str.len())\n",
    "  print('Emojis Sent', emojis)\n",
    "  #links consist of total links\n",
    "  links = sum(req_df[\"urlcount\"])   \n",
    "  print('Links Sent', links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fdf95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_emojis_list = list(set([a for b in messages_df.emoji for a in b]))\n",
    "total_emojis = len(total_emojis_list)\n",
    "\n",
    "total_emojis_list = list([a for b in messages_df.emoji for a in b])\n",
    "emoji_dict = dict(Counter(total_emojis_list))\n",
    "emoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "for i in emoji_dict:\n",
    "  print(i)\n",
    "  \n",
    "emoji_df = pd.DataFrame(emoji_dict, columns=['emoji', 'count'])\n",
    "import plotly.express as px\n",
    "fig = px.pie(emoji_df, values='count', names='emoji')\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88186191",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(review for review in messages_df.Message)\n",
    "print (\"There are {} words in all the messages.\".format(len(text)))\n",
    "stopwords = set(STOPWORDS)\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.figure( figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37deecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\"Indra\", \"tanya\"]\n",
    "for i in range(len(l)):\n",
    "  dummy_df = messages_df[messages_df['Author'] == l[i]]\n",
    "  text = \" \".join(review for review in dummy_df.Message)\n",
    "  stopwords = set(STOPWORDS)\n",
    "  #Generate a word cloud image\n",
    "  print('Author name',l[i])\n",
    "  wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
    "  #Display the generated image   \n",
    "  plt.figure( figsize=(10,5))\n",
    "  plt.imshow(wordcloud, interpolation='bilinear')\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d637c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
